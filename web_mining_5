
from bs4 import BeautifulSoup
import requests
import spacy
from collections import Counter

r = requests.get("https://www.gutenberg.org/files/1342/1342-0.txt")
nlp = spacy.load("en_core_web_sm")
soup = BeautifulSoup(r.content, 'html.parser')

text=str(soup.contents)
d = nlp(text)

# number of tokens 
token_counter = 0
for token in d:
    token_counter = token_counter + 1
print("Total number of tokens = ", token_counter)

# Verbs within the tokens
verb = 0
for t in d:
    if t.pos_ == "VERB":
        verb = verb + 1
print("Total number of verbs = ", verb)

ents = [str(ents) for ents in d.ents]
print(ents)
c = Counter(ents)
print(c.most_common())

sentences = 0
for sent in d.sents:
    sentences = sentences + 1
    #print(sent.text)
print("Number of sentences = ", sentences)

sentence = 0
for s in d.sents:
    sentence = sentence + 1
    if sentence == 15 :
        print("Fifteenth sentence is  ", s.text)
        d2 = nlp(sent.text)
        print("Vector representation of the first token of fifteenth sentence", d2[0].vector)

list = []
for s1 in d.sents:
    for s2 in d.sents:
        if len(str(s1.text).split()) > 9 and len(str(s2.text).split()) > 9:
                list.append(s1.text)
                list.append(s2.text)
                list.append(s1.similarity(s2))
            
list.sort(key= lambda x:x[2])
print(list)